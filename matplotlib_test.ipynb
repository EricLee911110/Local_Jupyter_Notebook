{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 300)\n",
    "for w in range(2, 6, 2):\n",
    "    plt.plot(x, np.sin(np.pi*x)*np.sin(2*w*np.pi*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5491a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s = np.array(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09210d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.shape)\n",
    "print(s+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffdcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[1,2,3,4,5,6,7,8,9,10,11]\n",
    "a = np.array(inputs)[None, :]\n",
    "print(a)\n",
    "\n",
    "min_value = np.amin(a)\n",
    "inputs_minus_min = a - min_value\n",
    "print(inputs_minus_min)\n",
    "\n",
    "max_value = np.amax(inputs_minus_min)\n",
    "inputs_div_max = inputs_minus_min / max_value\n",
    "print(inputs_div_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076593a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = [[1,2,3],\n",
    "      [4,5,6],\n",
    "      [7,8,9]]\n",
    "\n",
    "m2 = [[1,2],\n",
    "      [3,4],\n",
    "      [5,6]]\n",
    "\n",
    "result = np.dot(m1,m2)\n",
    "print(result)\n",
    "\n",
    "print(np.shape(m1))\n",
    "print(np.shape(m2)[1])\n",
    "print(np.sum(m1))\n",
    "\n",
    "print(np.count_nonzero(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44729482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = np.array([1,2])\n",
    "v2 = np.array([3,4])\n",
    "\n",
    "A = int(0.9 > 1.2)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24467ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -1.1\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b858bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    # Fill in code\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i], W, b)\n",
    "        if y[i] - y_hat == 1:  #Negatively misclassified\n",
    "            W, b = W + X[i].reshape(2,1)*learn_rate, b + 1*learn_rate\n",
    "        elif y[i] - y_hat == -1:  #Positively misclassifies \n",
    "            W, b = W - X[i].reshape(2,1)*learn_rate, b - 1*learn_rate\n",
    "    \n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41cb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#2-D Situation\n",
    "x1 = np.array([[1,2],\n",
    "               [3,4]]) \n",
    "x2 = np.array([[11,12],\n",
    "               [13,14]])\n",
    "print(np.dot(x1,x2))\n",
    "print(np.matmul(x1,x2))\n",
    "\n",
    "print('_____________')\n",
    "print(np.multiply(x1,x2))\n",
    "print(x1*x2)\n",
    "\n",
    "print('____________')\n",
    "print(np.inner(x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e38a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = np.array([1,2])\n",
    "x2 = np.array([3,4])\n",
    "\n",
    "print(np.dot(x1,x2))\n",
    "print(np.matmul(x1,x2))\n",
    "print(np.inner(x1,x2))\n",
    "result = 1 if np.matmul(x1,x2) > 0 else 0\n",
    "print(result)\n",
    "\n",
    "print(np.multiply(x1,x2))\n",
    "print(x1*x2)\n",
    "\n",
    "print('__________________')\n",
    "print(x1+x2*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1765206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = np.array([1,2])\n",
    "x2 = np.random.rand(2,1)\n",
    "\n",
    "print((np.dot(x1,x2) + 1)[0])\n",
    "\n",
    "print(x1)\n",
    "x1 = x1.reshape(2,1)\n",
    "print(x1)\n",
    "x2 = np.add(x1,x2)\n",
    "print(x2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d416e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "x = np.float_(a)\n",
    "print(x*(b+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8668c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1,2,3]\n",
    "print(x1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('cd0281-Introduction-to-Neural-Networks-with-PyTorch-master/gradient-descent/data.csv', header=None)\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(data[[0,1]])\n",
    "print(data[2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe501b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "print('weights:', weights)\n",
    "\n",
    "x1 = [1,2]\n",
    "\n",
    "print(np.matmul(weights, x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a217ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_features = 100\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53f951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd27e794",
   "metadata": {},
   "source": [
    "## Gradient Descent of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
    "#       the previous lesson to encourage you to come up with a more\n",
    "#       efficient solution. If you need a hint, check out the comments\n",
    "#       in solution.py from the previous lecture.\n",
    "\n",
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target\n",
    "\n",
    "        # Activation of the output unit\n",
    "        #   Notice we multiply the inputs and the weights here \n",
    "        #   rather than storing h as a separate variable \n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "        # The error, the target minus the network output\n",
    "        error = y - output\n",
    "\n",
    "        # The error term\n",
    "        #   Notice we calulate f'(h) here instead of defining a separate\n",
    "        #   sigmoid_prime function. This just makes it faster because we\n",
    "        #   can re-use the result of the sigmoid function stored in\n",
    "        #   the output variable\n",
    "        error_term = error * output * (1 - output)\n",
    "\n",
    "        # The gradient descent step, the error times the gradient times the inputs\n",
    "        del_w += error_term * x\n",
    "\n",
    "    # Update the weights here. The learning rate times the \n",
    "    # change in weights, divided by the number of records to average\n",
    "    weights += learnrate * del_w / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85166981",
   "metadata": {},
   "source": [
    "## Multilayer Perceptrons 4x3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf29a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "\n",
    "\n",
    "# TODO: Make a forward pass through the network\n",
    "\n",
    "hidden_layer_in = np.dot(X, weights_input_to_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_to_output)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec98ac",
   "metadata": {},
   "source": [
    "## Multilayer Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d39b0",
   "metadata": {},
   "source": [
    "### 1. One hidden unit and one output unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate output error\n",
    "error = target - output\n",
    "\n",
    "# TODO: Calculate error term for output layer\n",
    "output_error_term = error *output *(1 - output)\n",
    "\n",
    "# TODO: Calculate error term for hidden layer\n",
    "hidden_error_term = weights_hidden_output *output_error_term *hidden_layer_output *(1-hidden_layer_output)\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate *output_error_term *hidden_layer_output\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate *hidden_error_term *x[:,None]\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721eaa5",
   "metadata": {},
   "source": [
    "### 2. Two hidden units and one output unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "np.random.seed(21)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "n_hidden = 2  # number of hidden units\n",
    "epochs = 900\n",
    "learnrate = 0.005\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "# Initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        # TODO: Calculate the output\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(weights_hidden_output, hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # TODO: Calculate the network's prediction error\n",
    "        error = (y - output)\n",
    "\n",
    "        # TODO: Calculate error term for the output unit\n",
    "        output_error_term = (y - output) *output *(1-output)\n",
    "\n",
    "        ## propagate errors to hidden layer\n",
    "\n",
    "        # TODO: Calculate the hidden layer's contribution to the error\n",
    "        hidden_error = weights_hidden_output *output_error_term\n",
    "        \n",
    "        # TODO: Calculate the error term for the hidden layer\n",
    "        hidden_error_term = weights_hidden_output *output_error_term *hidden_output *(1 - hidden_output)\n",
    "        \n",
    "        # TODO: Update the change in weights\n",
    "        del_w_hidden_output += output_error_term *hidden_output\n",
    "        del_w_input_hidden += hidden_error_term *x [:,None]\n",
    "\n",
    "    # TODO: Update weights  (don't forget to division by n_records or number of samples)\n",
    "    weights_input_hidden += learnrate *del_w_input_hidden / n_records\n",
    "    weights_hidden_output += learnrate *del_w_hidden_output / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
